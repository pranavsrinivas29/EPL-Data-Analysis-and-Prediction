{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers sentence-transformers faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavsrinivasvenkatesh/anaconda3/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first CSV data (season-level data)\n",
    "season_data = pd.read_csv('epl_season_1993_2024.csv')\n",
    "season_data['text'] = season_data.apply(lambda row: f\"In {row['Season_End_Year']}, {row['Champion']} won the championship with {row['Total_Goals']} goals. The runner-up was {row['Runners']}.\", axis=1)\n",
    "\n",
    "# Load the second CSV data (match-level data)\n",
    "match_data = pd.read_csv('premier-league-matches.csv')\n",
    "match_data['text'] = match_data.apply(lambda row: f\"On {row['Date']}, {row['Home']} played against {row['Away']}. The match ended {row['HomeGoals']}-{row['AwayGoals']} with {row['FTR']} as the final result.\", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavsrinivasvenkatesh/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Combine both datasets into one DataFrame\n",
    "combined_data = pd.concat([season_data['text'], match_data['text']], ignore_index=True)\n",
    "\n",
    "# 2. Create Embeddings and FAISS Index\n",
    "\n",
    "# Initialize the model for creating embeddings\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create embeddings for the combined data\n",
    "embeddings = embedding_model.encode(combined_data.tolist())\n",
    "\n",
    "# Create a FAISS index for efficient similarity search\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "# 3. Save the FAISS Index and Embeddings\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(index, 'faiss_index.idx')\n",
    "\n",
    "# Save the combined data with embeddings\n",
    "combined_data.to_csv('combined_data_with_embeddings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the embedding model (if needed later)\n",
    "with open('model pickel/embedding_model.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pranavsrinivasvenkatesh/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained LLM (GPT-2 in this case)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Save the tokenizer and model for later use\n",
    "tokenizer.save_pretrained('gpt2_tokenizer')\n",
    "model.save_pretrained('gpt2_model')\n",
    "\n",
    "# 5. (Optional) Test the Saved Components\n",
    "\n",
    "# Test loading the FAISS index\n",
    "loaded_index = faiss.read_index('faiss_index.idx')\n",
    "\n",
    "# Test loading the combined data\n",
    "loaded_combined_data = pd.read_csv('combined_data_with_embeddings.csv')\n",
    "\n",
    "# Test loading the embedding model\n",
    "with open('model pickel/embedding_model.pkl', 'rb') as f:\n",
    "    loaded_embedding_model = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  In 1993, Manchester United won the championshi...\n",
      "1  In 1994, Manchester United won the championshi...\n",
      "2  In 1995, Blackburn Rovers won the championship...\n",
      "3  In 1996, Manchester United won the championshi...\n",
      "4  In 1997, Manchester United won the championshi...\n"
     ]
    }
   ],
   "source": [
    "# Test loading the GPT-2 model and tokenizer\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(\"gpt2_tokenizer\")\n",
    "loaded_model = AutoModelForCausalLM.from_pretrained(\"gpt2_model\")\n",
    "\n",
    "# Print a sample output to ensure everything is working correctly\n",
    "print(loaded_combined_data.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
